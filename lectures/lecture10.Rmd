---
title: "Stats 306: Lecture 10"
subtitle: "EDA: Visualizing and Quantifying Variation"
author: "Jayashree Ravi"
citation: "Content adapted from slides by Dr. Mark Fredrickson"
output:
  learnr::tutorial:
    progressive: true
    css: css/lecture.css
runtime: shiny_prerendered
---


```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(lubridate) # install.packages("lubridate") if you don't have this
wae <- read_tsv("data/WikiArt-Emotions-All.tsv.gz")
set.seed(2939394)
```


## Review

* Exploratory data analysis: trying to find the right questions
* Main questions:
  * What kind of variation for the measurements in in my sample?
  * What kinds of covariation among measurements (relationships)?
  


## WikiArt Emotions Database

```{r}
wae <- read_tsv("data/WikiArt-Emotions-All.tsv.gz")
dim(wae)
head(wae)
```


## Most liked piece of art

```{r}
favorite <- filter(wae, `Ave. art rating` == max(`Ave. art rating`))
favorite$Artist
favorite$Title
```

<center>

![Young mother contemplaing her sleeping child in candlelight](images/young_mother.jpg)

</center>

## ECDF for Rating

Recall that the **empirical cumulative distribution function** for a variable is a function that takes an input $x$ and gives back the proportion $X_i \le x$.

What proportion of works had negative (technically non-positive) ratings (i.e. $\hat F(0)$)

```{r}
summarize(wae, mean(`Ave. art rating` <= 0)) 
```

## Plotting the ECDF

```{r}
ggplot(wae, aes(x = `Ave. art rating`)) + stat_ecdf() + ylab("Proportion less than x")
```

 * x-axis is range of observed data
 * y-axis is 0 to 1

## From ECDF to Histogram


```{r}
k = 10
ggplot(wae, aes(x = `Ave. art rating`)) + geom_histogram(bins = k - 1)
```

```{r}
k = 10
ggplot(wae, aes(x = `Ave. art rating`)) + geom_histogram(bins = k - 1, aes(y = after_stat(count / sum(count))))
```

`after_stat` is an aesthetic expression that uses the variables calculated by the `stat`.

Which is this variable?



## Histograms, the importance of bin widths

A really bad idea:
```{r}
ggplot(wae, aes(x = `Ave. art rating`)) +
  geom_histogram(bins = 1)
```

Also probably a bad idea (though interesting!):

```{r}
ggplot(wae, aes(x = `Ave. art rating`)) +
  geom_histogram(bins = 500)
```

Goldilocks?
```{r}
ggplot(wae, aes(x = `Ave. art rating`)) +
  geom_histogram(bins = 50)
```



## Smoothing histograms: Density plots

When creating a histogram, I need two things

>* How wide are the bins
>* Where the bins will start

Rather than picking a particular starting location, let's think about averaging lots of starting locations (infinitely many). This yields a **density plot** (also known as a kernel density estimate plot):

```{r}
ggplot(wae, aes(x = `Ave. art rating`)) + geom_density()
```


## Density plots: smooth versus noisy

How does changing the bandwidth (bw) affect?

```{r}
ggplot(wae, aes(x = `Ave. art rating`)) + geom_density(bw = 5)
```

```{r}
ggplot(wae, aes(x = `Ave. art rating`)) + geom_density(bw = 0.03)
```


```{r}
bw.nrd0(wae$`Ave. art rating`) ## geom_density default
ggplot(wae, aes(x = `Ave. art rating`)) + geom_density()
```

A smaller bandwidth leads to a more sensitive estimate that captures smaller variations in the data.


## Investigating Year

Let's look at the histogram for year:

```{r}
class(wae$Year)
ggplot(wae, aes(x = as.numeric(Year))) + geom_histogram(binwidth = 10) 
```

* Most of the works from the 19th and 20th century
* We see we get some warnings
* No observations in 18th century?



## Digging in more

Recall R's special "missing value" indicator is `NA`. There is also `NaN` which is used when try to compute undefined values (e.g.. 1/0) The `is.na` method tells us if a value is marked as missing/NaN.


What do some of these look like?
```{r}
filter(wae, is.na(as.numeric(Year))) |> sample_n(10) |> select(Year)
```

## Dealing with missing values

Can we find a way to get years? We could try getting the first 4 digits.

```{r}
wae_year <- mutate(wae, 
                   year4 = substring(Year, 1, 4),
                   year_num = as.numeric(Year),
                   year4_num = as.numeric(year4))

summarize(wae_year, mean(is.na(year_num)), mean(is.na(year4_num)))

ggplot(wae_year, aes(x = year4_num)) + geom_histogram(binwidth = 10)
```

## Other ways of dealing with missingness

* Case-wise deletion: drop all rows with missing values for variables we care about (`drop_na`, many functions have `na.rm` option)
* Simple imputation (make guesses, such as the mean of all other values)
* Model based imputation

## Exercise

Use `drop_na` to remove rows with years that are missing after using `as.numeric` and compare to original data using `dim`
```{r missing, exercise = TRUE}
## wae is the name of the table, Year is the column
```

```{r missing-solution}
wae |> mutate(year = as.numeric(Year)) |> drop_na() |> dim()
wae |> dim()
```



## Plot Happiness

```{r}
ggplot(wae, aes(x = `Art (image+title): happiness`)) + geom_histogram(bins = 100)
```


## Covariation

We see that these works of art *vary* in their "happiness" ratings. What differences are there between the ones showing high happiness compared to ones showing low happiness ratings? 

This is asking about **covariation**, how do more than one measurement vary together? 

How we deal with covariation depends on the types of data we have (categorical, quantitative/continuous).

##  Joint Distributions and Conditional distributions

For two variables, $X$ and $Y$, the **joint distribution** tells us how often each possible combination of $(X, Y)$ appears in our data set. 

If we fix one variable, say $X$, at a particular value, say $x$, then look at all $Y$ such that $X = x$, we get the **conditional distribution**.

Joint distributions contain slightly more information, but conditional distributions are often a little easier to work with. In particular, it's often easier to condition on categorical variables.

## Stratifying data

For the "happiness" rating, since the values are close to 0.1, 0.2, etc., let's round and **stratify** (group):

```{r}
mutate(wae, happy_round = round(`Art (image+title): happiness`, 1)) |>
  group_by(happy_round) -> wae_happy_strat

summarize(wae_happy_strat, n() / nrow(wae_happy_strat))
```

This shows the marginal distribution of `happy_round`

## Using stratification

One thing we've seen already is looking at summaries of the **conditional distributions** of rating given happiness.

```{r}
summarize_at(wae_happy_strat, "Ave. art rating", list(med = median, me = mean, sd = sd))
```

## Violin plot

To visualize all the conditional distributions
```{r}
ggplot(wae_happy_strat, aes(x = factor(happy_round), y = `Ave. art rating`)) + geom_violin()
```

Q: What information do we lose with this plot of conditional distributions that we know about the distribution of happiness?

## Joint distribution of two quantitative

```{r}
ggplot(wae, aes(x = `Art (image+title): happiness`, y = `Ave. art rating`)) + geom_point()
```

## Joint distributions for two quantitative - another example

```{r}
ggplot(wae_year, aes(x = as.numeric(year4), y = `Ave. art rating`)) + geom_point()
```

## 2D histogram

```{r warning = FALSE}
ggplot(wae_year, aes(x = as.numeric(year4), y = `Ave. art rating`)) + geom_bin2d()
```

## Stratifying on year categories

```{r warning = FALSE}
mutate(wae_year, year_cat = cut(as.numeric(year4), 8, labels = c(14:21))) |>
  ggplot(aes(x = year_cat, y = `Ave. art rating`)) + geom_violin()
```

## Locally weighted least squares (loess) 

What if we don't want to stratify, can we still look at conditional distributions of one continuous variable given another?

**Locally weighted least squares** or loess (smoothed trend lines) gives us a way:

```{r warning = FALSE}
ggplot(wae_year, aes(x = as.numeric(year4), y = `Ave. art rating`)) + geom_point() + stat_smooth()
```

## Models for relationships

We tend to hit our limit for showing joint distributions with two variables (maybe three). We also want to describe what we observe with more specific numerical quantities (like loess lines). For these purposes we need to employ **models**.

Some questions we might approach with models:

* Could this pattern be due to coincidence (i.e. random chance)?
* How can you describe the relationship implied by the pattern?
* How strong is the relationship implied by the pattern?
* What other variables might affect the relationship?
* Does the relationship change if you look at individual subgroups of the data?

## Next time

>* More EDA
